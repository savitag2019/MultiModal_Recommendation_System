{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a899f9",
   "metadata": {},
   "source": [
    "## 1. Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1f9ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/buchi_env/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "import zipfile, os, urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78e9dd",
   "metadata": {},
   "source": [
    "## 2. Download and Load MovieLens 100K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5448a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract MovieLens 100K\n",
    "def download_movielens():\n",
    "    if not os.path.exists('ml-100k/u.data'):\n",
    "        urllib.request.urlretrieve('http://files.grouplens.org/datasets/movielens/ml-100k.zip', 'ml-100k.zip')\n",
    "        with zipfile.ZipFile('ml-100k.zip', 'r') as z:\n",
    "            z.extractall()\n",
    "download_movielens()\n",
    "\n",
    "# Load ratings and items\n",
    "def load_data():\n",
    "    ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    items = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1', header=None,\n",
    "                        names=['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "                               'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', \n",
    "                               'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n",
    "                               'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
    "    return ratings, items\n",
    "\n",
    "ratings, items = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b956",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing: Extract Genres and Feature Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48040fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_cols = items.columns[5:]\n",
    "items['genres'] = items[genre_cols].apply(lambda row: list(genre_cols[row==1]), axis=1)\n",
    "item_genres = dict(zip(items.movie_id, items.genres))\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.fit((x for x in ratings['user_id']), (x for x in ratings['item_id']))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_features = mlb.fit_transform(items['genres'])\n",
    "item_features = [(item_id, item_genres[item_id]) for item_id in items.movie_id]\n",
    "dataset.fit_partial(items=(x for x, _ in item_features), item_features=(x for x in mlb.classes_))\n",
    "\n",
    "interactions, _ = dataset.build_interactions([(uid, iid) for uid, iid in zip(ratings.user_id, ratings.item_id)])\n",
    "item_features_matrix = dataset.build_item_features(item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4630bd",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split and Build Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b045b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "train_interactions, _ = dataset.build_interactions([(uid, iid) for uid, iid in zip(train_ratings.user_id, train_ratings.item_id)])\n",
    "test_interactions, _ = dataset.build_interactions([(uid, iid) for uid, iid in zip(test_ratings.user_id, test_ratings.item_id)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1ff09",
   "metadata": {},
   "source": [
    "## 5. Train LightFM Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a1953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x11be50370>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train LightFM Hybrid Model\n",
    "model = LightFM(loss='warp', no_components=30)\n",
    "model.fit(train_interactions, item_features=item_features_matrix, epochs=10, num_threads=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca16d8e",
   "metadata": {},
   "source": [
    "## 6. Define Evaluation Metrics (Precision@k, NDCG, Hit Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561bc297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Precision@10 (Train): 0.5981\n",
      "ðŸ“Š Precision@10 (Test): 0.1263\n",
      "ðŸ“ˆ AUC Score (Test): 0.9023\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, train_interactions, test_interactions, item_features):\n",
    "    prec_train = precision_at_k(model, train_interactions, item_features=item_features, k=10).mean()\n",
    "    prec_test = precision_at_k(model, test_interactions, item_features=item_features, k=10).mean()\n",
    "    auc = auc_score(model, test_interactions, item_features=item_features).mean()\n",
    "    print(f\"ðŸ“Š Precision@10 (Train): {prec_train:.4f}\")\n",
    "    print(f\"ðŸ“Š Precision@10 (Test): {prec_test:.4f}\")\n",
    "    print(f\"ðŸ“ˆ AUC Score (Test): {auc:.4f}\")\n",
    "\n",
    "evaluate_model(model, train_interactions, test_interactions, item_features_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359b8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Hit Rate@10 (Test): 0.7117\n"
     ]
    }
   ],
   "source": [
    "def hit_rate_at_k(model, interactions, item_features, k=10):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    for user_id in range(interactions.shape[0]):\n",
    "        true_items = interactions.tocsr()[user_id].indices\n",
    "        if len(true_items) == 0:\n",
    "            continue\n",
    "        scores = model.predict(user_id, np.arange(interactions.shape[1]), item_features=item_features)\n",
    "        top_items = np.argsort(-scores)[:k]\n",
    "        hits += any(item in top_items for item in true_items)\n",
    "        total += 1\n",
    "    return hits / total if total > 0 else 0\n",
    "\n",
    "hit_rate = hit_rate_at_k(model, test_interactions, item_features_matrix, k=10)\n",
    "print(f\"ðŸŽ¯ Hit Rate@10 (Test): {hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43533cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸ NDCG@10 (Test): 0.3784\n"
     ]
    }
   ],
   "source": [
    "def ndcg_at_k(model, interactions, item_features, k=10):\n",
    "    ndcgs = []\n",
    "    for user_id in range(interactions.shape[0]):\n",
    "        true_items = interactions.tocsr()[user_id].indices\n",
    "        if len(true_items) == 0:\n",
    "            continue\n",
    "        scores = model.predict(user_id, np.arange(interactions.shape[1]), item_features=item_features)\n",
    "        top_items = np.argsort(-scores)[:k]\n",
    "        relevance = [1 if item in true_items else 0 for item in top_items]\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        dcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(relevance)])\n",
    "        idcg = sum([rel / np.log2(idx + 2) for idx, rel in enumerate(ideal_relevance)])\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.mean(ndcgs) if ndcgs else 0\n",
    "\n",
    "ndcg_score_k = ndcg_at_k(model, test_interactions, item_features_matrix, k=10)\n",
    "print(f\"ðŸŒŸ NDCG@10 (Test): {ndcg_score_k:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5bdc3",
   "metadata": {},
   "source": [
    "## 7. Recommend Top-N Movies for a Known User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c831d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for known user 3:\n",
      "- Game, The (1997)\n",
      "- Scream (1996)\n",
      "- L.A. Confidential (1997)\n",
      "- Air Force One (1997)\n",
      "- Boogie Nights (1997)\n",
      "- Lost Highway (1997)\n",
      "- Cop Land (1997)\n",
      "- Devil's Advocate, The (1997)\n",
      "- Full Monty, The (1997)\n",
      "- Contact (1997)\n"
     ]
    }
   ],
   "source": [
    "uid_map, iid_map, _ = dataset.mapping()[0], dataset.mapping()[2], dataset.mapping()[1]\n",
    "rev_iid_map = {v: k for k, v in iid_map.items()}\n",
    "\n",
    "def recommend_known_user(model, user_id, k=10):\n",
    "    scores = model.predict(uid_map[user_id], np.arange(len(iid_map)), item_features=item_features_matrix)\n",
    "    top_items = np.argsort(-scores)[:k]\n",
    "    print(f\"Top {k} recommendations for known user {user_id}:\")\n",
    "    for i in top_items:\n",
    "        title = items[items.movie_id == rev_iid_map[i]]['title'].values[0]\n",
    "        print('-', title)\n",
    "\n",
    "recommend_known_user(model, user_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b42558-d0a1-47ab-b032-ca6beb82fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for known user 10:\n",
      "- Fargo (1996)\n",
      "- Amadeus (1984)\n",
      "- English Patient, The (1996)\n",
      "- Silence of the Lambs, The (1991)\n",
      "- Schindler's List (1993)\n",
      "- One Flew Over the Cuckoo's Nest (1975)\n",
      "- Citizen Kane (1941)\n",
      "- Pulp Fiction (1994)\n",
      "- Clockwork Orange, A (1971)\n",
      "- Apocalypse Now (1979)\n"
     ]
    }
   ],
   "source": [
    "recommend_known_user(model, user_id=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac939c6",
   "metadata": {},
   "source": [
    "## 8. Cold-Start Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526eaf7",
   "metadata": {},
   "source": [
    "### 8.1 Recommend Top Popular Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4550ae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 popular movies for unknown user (cold start):\n",
      "- Star Wars (1977)\n",
      "- Contact (1997)\n",
      "- Fargo (1996)\n",
      "- Return of the Jedi (1983)\n",
      "- Liar Liar (1997)\n",
      "- English Patient, The (1996)\n",
      "- Scream (1996)\n",
      "- Toy Story (1995)\n",
      "- Air Force One (1997)\n",
      "- Independence Day (ID4) (1996)\n"
     ]
    }
   ],
   "source": [
    "top_popular = ratings.groupby('item_id').size().sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 popular movies for unknown user (cold start):\")\n",
    "for iid in top_popular.index:\n",
    "    title = items[items.movie_id == iid]['title'].values[0]\n",
    "    print('-', title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442149d",
   "metadata": {},
   "source": [
    "### 8.2 Recommend Based on Genre Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "451cd72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top genre-based recommendations:\n",
      "- GoldenEye (1995)\n",
      "- Bulletproof (1996)\n",
      "- Power 98 (1995)\n",
      "- Fled (1996)\n",
      "- Daylight (1996)\n",
      "- Arrival, The (1996)\n",
      "- Shadow, The (1994)\n",
      "- Rising Sun (1993)\n",
      "- Program, The (1993)\n",
      "- Menace II Society (1993)\n"
     ]
    }
   ],
   "source": [
    "# Cold-start: Recommend based on genre similarity for a new user with genre preference\n",
    "def recommend_by_genre(preferred_genres, items_df, k=10):\n",
    "    matches = items_df[items_df[preferred_genres].sum(axis=1) > 0]\n",
    "    top = matches.groupby('movie_id').size().sort_values(ascending=False).head(k)\n",
    "    print(\"Top genre-based recommendations:\")\n",
    "    for idx in top.index:\n",
    "        title = items_df[items_df.movie_id == idx]['title'].values[0]\n",
    "        print(f\"- {title}\")\n",
    "\n",
    "# Example: Recommend for a new user who likes 'Action' and 'Sci-Fi'\n",
    "recommend_by_genre(['Action', 'Sci-Fi'], items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbf1de",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6afb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Evaluation on Test Set\n",
      "ðŸ“Š Precision@10 (Train): 0.5981\n",
      "ðŸ“Š Precision@10 (Test): 0.1263\n",
      "ðŸ“ˆ AUC Score (Test): 0.9023\n",
      "NDCG@10 on test set: 0.3784\n",
      "Hit Rate@10 on test set: 0.7117\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"ðŸ“Š Model Evaluation on Test Set\")\n",
    "evaluate_model(model, train_interactions, test_interactions, item_features_matrix)\n",
    "\n",
    "# Compute NDCG and Hit Rate on test interactions\n",
    "ndcg_score_val = ndcg_at_k(model, test_interactions, item_features_matrix, k=10)\n",
    "hit_rate_val = hit_rate_at_k(model, test_interactions, item_features_matrix, k=10)\n",
    "\n",
    "print(f\"NDCG@10 on test set: {ndcg_score_val:.4f}\")\n",
    "print(f\"Hit Rate@10 on test set: {hit_rate_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799eb52",
   "metadata": {},
   "source": [
    "## 10. Scalability Considerations for Production Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f6f59",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To handle millions of users/items in production:\n",
    "\n",
    "- **Approximate Nearest Neighbors**: Use `FAISS` or `Annoy` to store dense item embeddings for fast similarity search.\n",
    "- **Distributed Training**: Train collaborative models with `Spark MLlib` (ALS) or GPU-accelerated versions of `LightFM`.\n",
    "- **Incremental Updates**: Store user/item vectors in Redis and update embeddings incrementally with new interactions.\n",
    "- **Microservice Architecture**: Separate collaborative filtering and content-based recommenders into scalable services with API layers.\n",
    "- **Batch Pipelines**: Use `Feast` or custom pipelines for feature ingestion, nightly retraining, and reindexing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
